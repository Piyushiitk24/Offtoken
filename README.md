# TokenForge - Professional AI Token Counter

<div align="center">

![TokenForge](https://img.shields.io/badge/TokenForge-AI%20Tool-rainbow)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-Latest-red)
![License](https://img.shields.io/badge/License-MIT-green)

**ğŸŒˆ Professional AI token counter with beautiful UI for OpenAI models**

[ğŸš€ Quick Start](#quick-start) â€¢ [ğŸ“Š Features](#features) â€¢ [ğŸ¯ Use Cases](#use-cases) â€¢ [ğŸ“– Documentation](#documentation)

</div>

---

## ğŸš€ Quick Start

Get TokenForge running in 2 minutes:

```bash
git clone https://github.com/Piyushiitk24/Offtoken.git
cd Offtoken
python3 setup.py
```

Your browser will automatically open with the TokenForge interface! ğŸ‰

## ğŸ“Š Features

### âœ¨ **Core Functionality**
- **Accurate Token Counting** - Uses authentic OpenAI tokenizers
- **API Cost Estimation** - Calculate costs before making API calls
- **Multi-Model Support** - GPT-4, GPT-3.5, GPT-3, and more
- **Document Processing** - PDF, DOCX, TXT file support
- **Professional Reports** - Export detailed analytics

### ğŸ¨ **Beautiful Interface**
- **Modern Design** - Clean, professional UI with subtle theming
- **Responsive Layout** - Works perfectly on all screen sizes
- **Interactive Analytics** - Real-time visualizations and metrics
- **Easy Navigation** - Intuitive user experience

## ğŸ“Š Supported Models

| Model | Tokenizer | Best For |
|-------|-----------|----------|
| **GPT-4** | `gpt-4` | Most accurate GPT-4 API usage |
| **GPT-3.5 Turbo** | `gpt-3.5-turbo` | ChatGPT and GPT-3.5 APIs |
| **GPT-3** | `text-davinci-003` | Legacy GPT-3 applications |
| **cl100k_base** | `cl100k_base` | GPT-4, GPT-3.5 compatible |
| **p50k_base** | `p50k_base` | GPT-3, Codex compatible |

## ğŸ¯ Use Cases

### ğŸ’° **API Cost Optimization**
- Pre-flight cost estimation before expensive API calls
- Budget planning for large-scale AI projects
- Prompt optimization to reduce token usage

### ğŸ“ **Context Window Management**
- Ensure prompts fit within model limits (8K/32K tokens)
- Optimize content length for specific models
- Avoid costly API failures due to token limits

### ğŸ”¬ **Research & Development**
- Compare tokenization across different models
- Analyze text compression ratios and efficiency
- Academic research on language model behavior

### ğŸ¨ **Content Creation**
- Optimize marketing copy for token efficiency
- Streamline documentation and technical content
- Perfect prompt engineering for specific token counts

## ğŸ“± How to Use

1. **ğŸš€ Launch**: Run `python3 setup.py`
2. **ğŸ¤– Select Model**: Choose your target tokenizer
3. **ğŸ“„ Input Content**: Upload documents or paste text
4. **ğŸ’° Set Pricing**: Configure cost estimation (optional)
5. **ğŸ“Š Analyze**: View detailed token counts and analytics
6. **ğŸ“¥ Export**: Download professional reports

## ğŸ› ï¸ Requirements

- **Python 3.8+** (tested with 3.11-3.13)
- **Operating System**: macOS, Linux, Windows
- **Memory**: 512MB RAM minimum
- **Dependencies**: Automatically installed by setup script

## ğŸ“– Documentation

- **[GitHub Pages](https://piyushiitk24.github.io/Offtoken/)** - Full documentation
- **[Issues](https://github.com/Piyushiitk24/Offtoken/issues)** - Bug reports and feature requests
- **[Discussions](https://github.com/Piyushiitk24/Offtoken/discussions)** - Community support

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

<div align="center">

**Made with â¤ï¸ for the AI development community**

[â­ Star this repo](https://github.com/Piyushiitk24/Offtoken) if you find it useful!

</div>
