# TokenForge - Professional AI Token Counter

<div align="center">

![TokenForge](https://img.shields.io/badge/TokenForge-AI%20Tool-rainbow)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-Latest-red)
![License](https://img.shields.io/badge/License-MIT-green)

**🌈 Professional AI token counter with beautiful UI for OpenAI models**

[🚀 Quick Start](#quick-start) • [📊 Features](#features) • [🎯 Use Cases](#use-cases) • [📖 Documentation](#documentation)

</div>

---

## 🚀 Quick Start

Get TokenForge running in 2 minutes:

```bash
git clone https://github.com/Piyushiitk24/Offtoken.git
cd Offtoken
python3 setup.py
```

Your browser will automatically open with the TokenForge interface! 🎉

## 📊 Features

### ✨ **Core Functionality**
- **Accurate Token Counting** - Uses authentic OpenAI tokenizers
- **API Cost Estimation** - Calculate costs before making API calls
- **Multi-Model Support** - GPT-4, GPT-3.5, GPT-3, and more
- **Document Processing** - PDF, DOCX, TXT file support
- **Professional Reports** - Export detailed analytics

### 🎨 **Beautiful Interface**
- **Modern Design** - Clean, professional UI with subtle theming
- **Responsive Layout** - Works perfectly on all screen sizes
- **Interactive Analytics** - Real-time visualizations and metrics
- **Easy Navigation** - Intuitive user experience

## 📊 Supported Models

| Model | Tokenizer | Best For |
|-------|-----------|----------|
| **GPT-4** | `gpt-4` | Most accurate GPT-4 API usage |
| **GPT-3.5 Turbo** | `gpt-3.5-turbo` | ChatGPT and GPT-3.5 APIs |
| **GPT-3** | `text-davinci-003` | Legacy GPT-3 applications |
| **cl100k_base** | `cl100k_base` | GPT-4, GPT-3.5 compatible |
| **p50k_base** | `p50k_base` | GPT-3, Codex compatible |

## 🎯 Use Cases

### 💰 **API Cost Optimization**
- Pre-flight cost estimation before expensive API calls
- Budget planning for large-scale AI projects
- Prompt optimization to reduce token usage

### 📏 **Context Window Management**
- Ensure prompts fit within model limits (8K/32K tokens)
- Optimize content length for specific models
- Avoid costly API failures due to token limits

### 🔬 **Research & Development**
- Compare tokenization across different models
- Analyze text compression ratios and efficiency
- Academic research on language model behavior

### 🎨 **Content Creation**
- Optimize marketing copy for token efficiency
- Streamline documentation and technical content
- Perfect prompt engineering for specific token counts

## 📱 How to Use

1. **🚀 Launch**: Run `python3 setup.py`
2. **🤖 Select Model**: Choose your target tokenizer
3. **📄 Input Content**: Upload documents or paste text
4. **💰 Set Pricing**: Configure cost estimation (optional)
5. **📊 Analyze**: View detailed token counts and analytics
6. **📥 Export**: Download professional reports

## 🛠️ Requirements

- **Python 3.8+** (tested with 3.11-3.13)
- **Operating System**: macOS, Linux, Windows
- **Memory**: 512MB RAM minimum
- **Dependencies**: Automatically installed by setup script

## 📖 Documentation

- **[GitHub Pages](https://piyushiitk24.github.io/Offtoken/)** - Full documentation
- **[Issues](https://github.com/Piyushiitk24/Offtoken/issues)** - Bug reports and feature requests
- **[Discussions](https://github.com/Piyushiitk24/Offtoken/discussions)** - Community support

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🤝 Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

<div align="center">

**Made with ❤️ for the AI development community**

[⭐ Star this repo](https://github.com/Piyushiitk24/Offtoken) if you find it useful!

</div>
